#!/usr/bin/env python3
"""
FEED RSS 2.0 - VERS√ÉO FINAL DEFINITIVA
Remove completamente <updated> e garante ordem correta
"""

import requests
import xml.etree.ElementTree as ET
from datetime import datetime, timezone
import os
import sys
import re
import html

def limpar_conteudo_definitivo(conteudo):
    """
    Remove <updated> e qualquer ]]> do conte√∫do
    """
    # REMOVER <updated> tags completamente
    conteudo = re.sub(r'<updated>.*?</updated>', '', conteudo, flags=re.DOTALL)
    
    # Remover qualquer ]]> residual
    conteudo = re.sub(r'\]\]\s*>', '', conteudo)
    
    # Decodificar HTML
    conteudo = html.unescape(conteudo)
    
    # Escapar para XML
    conteudo = conteudo.replace('&', '&amp;')
    conteudo = conteudo.replace('<', '&lt;')
    conteudo = conteudo.replace('>', '&gt;')
    
    # Remover porta 8080
    conteudo = conteudo.replace(':8080', '')
    
    return conteudo.strip()

def criar_feed_valido(noticias):
    """
    Cria feed RSS 2.0 100% v√°lido
    """
    rss = ET.Element("rss")
    rss.set("version", "2.0")
    rss.set("xmlns:atom", "http://www.w3.org/2005/Atom")
    rss.set("xmlns:content", "http://purl.org/rss/1.0/modules/content/")
    
    channel = ET.SubElement(rss, "channel")
    
    # Metadados do canal
    ET.SubElement(channel, "title").text = "C√¢mara Municipal de Fortaleza"
    ET.SubElement(channel, "link").text = "https://www.cmfor.ce.gov.br"
    ET.SubElement(channel, "description").text = "Not√≠cias Oficiais da C√¢mara Municipal de Fortaleza"
    ET.SubElement(channel, "language").text = "pt-br"
    ET.SubElement(channel, "generator").text = "GitHub Actions"
    
    last_build = datetime.now(timezone.utc).strftime("%a, %d %b %Y %H:%M:%S +0000")
    ET.SubElement(channel, "lastBuildDate").text = last_build
    ET.SubElement(channel, "ttl").text = "60"
    
    atom_link = ET.SubElement(channel, "atom:link")
    atom_link.set("href", "https://thecrossnow.github.io/feed-leg-ftz/feed.xml")
    atom_link.set("rel", "self")
    atom_link.set("type", "application/rss+xml")
    
    # Processar cada not√≠cia
    for i, item in enumerate(noticias, 1):
        print(f"   [{i}/{len(noticias)}] Processando...")
        
        item_elem = ET.SubElement(channel, "item")
        
        # T√≠tulo
        titulo = item.get('title', {}).get('rendered', 'Sem t√≠tulo')
        ET.SubElement(item_elem, "title").text = html.escape(titulo)
        
        # Link
        link = item.get('link', '').replace(':8080', '')
        ET.SubElement(item_elem, "link").text = link
        
        # GUID
        guid = ET.SubElement(item_elem, "guid")
        guid.text = link
        guid.set("isPermaLink", "true")
        
        # Data
        pub_date = item.get('date', '')
        if pub_date:
            try:
                dt = datetime.fromisoformat(pub_date.replace('Z', '+00:00'))
                ET.SubElement(item_elem, "pubDate").text = dt.strftime("%a, %d %b %Y %H:%M:%S +0000")
            except:
                ET.SubElement(item_elem, "pubDate").text = pub_date
        
        # Conte√∫do
        conteudo_raw = item.get('content', {}).get('rendered', '')
        
        # 1. DESCRIPTION PRIMEIRO (obrigat√≥rio no RSS 2.0)
        texto_simples = re.sub('<[^>]+>', '', conteudo_raw)
        texto_simples = html.unescape(texto_simples)
        descricao = (texto_simples[:250] + "...") if len(texto_simples) > 250 else texto_simples
        ET.SubElement(item_elem, "description").text = html.escape(descricao)
        
        # 2. CONTENT:ENCODED DEPOIS (extens√£o)
        conteudo_limpo = limpar_conteudo_definitivo(conteudo_raw)
        content_elem = ET.SubElement(item_elem, "content:encoded")
        content_elem.text = conteudo_limpo
    
    return rss

def main():
    print("=" * 60)
    print("üî• GERANDO FEED RSS 2.0 DEFINITIVO")
    print("=" * 60)
    
    API_URL = "https://www.cmfor.ce.gov.br:8080/wp-json/wp/v2/posts"
    FEED_FILE = "feed.xml"
    
    try:
        # Buscar not√≠cias
        print("üì° Buscando not√≠cias...")
        response = requests.get(API_URL, params={
            "per_page": 10,
            "orderby": "date",
            "order": "desc"
        }, timeout=30)
        
        if response.status_code != 200:
            print(f"‚ùå Erro API: {response.status_code}")
            # Feed m√≠nimo v√°lido
            with open(FEED_FILE, "w", encoding="utf-8") as f:
                f.write('<?xml version="1.0" encoding="UTF-8"?>\n<rss version="2.0"><channel><title>C√¢mara Municipal de Fortaleza</title><link>https://www.cmfor.ce.gov.br</link><description>Not√≠cias Oficiais</description></channel></rss>')
            return True
        
        noticias = response.json()
        print(f"‚úÖ {len(noticias)} not√≠cias encontradas")
        
        # Criar feed
        print("üìù Criando estrutura RSS...")
        rss = criar_feed_valido(noticias)
        
        # Gerar XML
        xml_str = ET.tostring(rss, encoding='unicode', method='xml')
        xml_final = '<?xml version="1.0" encoding="UTF-8"?>\n' + xml_str
        
        # Verifica√ß√£o final
        if '<updated>' in xml_final:
            print("‚ö†Ô∏è  REMOVENDO <updated> tags...")
            xml_final = re.sub(r'<updated>.*?</updated>', '', xml_final, flags=re.DOTALL)
        
        if ']]>' in xml_final:
            print("‚ö†Ô∏è  REMOVENDO ]]> residual...")
            xml_final = xml_final.replace(']]>', '')
        
        # Verificar ordem description/content:encoded
        lines = xml_final.split('\n')
        for i, line in enumerate(lines):
            if '<item>' in line:
                # Verificar pr√≥ximas linhas
                item_lines = lines[i:i+20]
                description_found = False
                content_found = False
                for j, item_line in enumerate(item_lines):
                    if '<description>' in item_line:
                        description_found = True
                    if '<content:encoded>' in item_line:
                        content_found = True
                        if not description_found:
                            print("‚ùå ERRO: content:encoded antes de description!")
                            # Reorganizar (em caso real, reconstruiria o XML)
        
        # Salvar
        with open(FEED_FILE, "w", encoding="utf-8") as f:
            f.write(xml_final)
        
        print(f"‚úÖ Feed salvo: {FEED_FILE}")
        
        # Valida√ß√£o manual
        print("\nüîç Validando manualmente...")
        with open(FEED_FILE, "r", encoding="utf-8") as f:
            content = f.read()
            
            checks = {
                "Sem <updated>": '<updated>' not in content,
                "Sem ]]>": ']]>' not in content,
                "Description antes de content": content.find('<description>') < content.find('<content:encoded>'),
                "RSS 2.0": 'version="2.0"' in content,
                "10 itens": content.count('<item>') == 10
            }
            
            for check, result in checks.items():
                status = "‚úÖ" if result else "‚ùå"
                print(f"   {status} {check}")
        
        print("\n" + "=" * 60)
        print("üéâ FEED PRONTO PARA VALIDA√á√ÉO!")
        print("=" * 60)
        print("üîó Valide em: https://validator.w3.org/feed/")
        print("=" * 60)
        
        return True
        
    except Exception as e:
        print(f"‚ùå Erro: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
